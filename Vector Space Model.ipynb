{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "class VSM:\n",
    "\n",
    "    #D1 = \"English tutorial and fast track \"\n",
    "    D1 = \"English tutorial and fast track learning latent semantic indexing Book on semantic indexing Advance in structure and semantic indexing Analysis Analysis of latent structure\"\n",
    "    D2 = \"learning latent semantic indexing\"\n",
    "    D3 = \"Book on semantic indexing\"\n",
    "    D4 = \"Advance in structure and semantic indexing\"\n",
    "    D5 = \"Analysis Analysis of latent structure\"\n",
    "    Q1=\"latent learning\"\n",
    "    Q2=\"Advance structure\"\n",
    "    Q3=\"learning latent\"\n",
    "    Q4=\"analysis\"\n",
    "    Data = {\"DOC1\": D1,\n",
    "            \"DOC2\": D2, \n",
    "            \"DOC3\": D3, \n",
    "            \"DOC4\": D4,\n",
    "            \"DOC5\": D5  \n",
    "           }\n",
    "    \n",
    "                \n",
    "    def _init_(self,Q):\n",
    "        self.Q=Q\n",
    "        self.Data[\"Q\"]=self.Q\n",
    "\n",
    "    StopWords = {\"ON\" , \"on\" , \n",
    "                 \"OF\" , \"of\" ,\n",
    "                 \"THE\", \"the\",\n",
    "                 \"AN\" , \"an\" ,\n",
    "                 \"A\"  , \"a\",\n",
    "                 \"IN\" , \"in\"  }\n",
    "     \n",
    "        \n",
    "\n",
    "    BooleanOperator = {'AND', 'OR', 'NOT','and','or','not'}\n",
    "    ## list of terms from the Data file collection\n",
    "    Ti=[]\n",
    "    #list of Distinct Terms\n",
    "    ti=[]\n",
    "    #Document collection terms\n",
    "    Di={}\n",
    "    #TermDocumentIncidenceMatrix \n",
    "    TerDoc_frequency_Matrix=None\n",
    "    #document frequency df\n",
    "    df=None\n",
    "    #\n",
    "    idf=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Vector Space Modal\n",
    "\n",
    "### Documents collection:\n",
    "\n",
    "    1. Doc1= \"English tutorial and fast track\"\n",
    "    2. Doc2 = \"learning latent semantic indexing\"\n",
    "    3. Doc3 = \"Book on semantic indexing\"\n",
    "    4. Doc4 = \"Advance in structure and semantic indexing\"\n",
    "    5. Doc5 = \"Analysis of latent structures\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def add_Query_data(Q):\n",
    "        VSM.Data[\"Q\"]=Q\n",
    "    def delete_Query_from_Data():\n",
    "        VSM.Data.pop('Q')\n",
    "    \n",
    "    #removing Stop Words\n",
    "    def RemoveStopWords(sentence):\n",
    "        terms=[]\n",
    "        for term in sentence.split() : \n",
    "            if term not in VSM.StopWords :\n",
    "                terms.append(term)\n",
    "        return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    #list of Terms\n",
    "    def Terms(Data):\n",
    "        Terms=[]\n",
    "        for doc in Data:\n",
    "            Terms.append(RemoveStopWords(Data[doc].upper()))\n",
    "        Terms=[item for sublist in Terms for item in sublist]\n",
    "        return Terms\n",
    "    #list of Distinct Terms\n",
    "    def Distinctterms(Terms):\n",
    "        DistinctTerms=[]\n",
    "        for d in Terms :\n",
    "            if d not in DistinctTerms:\n",
    "                DistinctTerms.append(d)\n",
    "        return DistinctTerms\n",
    "\n",
    "    #Document collection terms\n",
    "    def DocumentColection(Data):\n",
    "        DocCollect={}\n",
    "        for doc in Data:\n",
    "            if doc not in VSM.BooleanOperator :\n",
    "                DocCollect[doc]=RemoveStopWords(Data[doc].upper())\n",
    "        return DocCollect\n",
    "\n",
    "    def displayDict(D):\n",
    "        print(\"\\n\")\n",
    "        for i in D:\n",
    "            print (\"\\n\",i , \" : \" ,D[i],\"\\n\")\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def TermDocfrequencyMatrix(DocumentTermsCollection ,DistinctTerms):\n",
    "        nbr_terms=len(DistinctTerms)\n",
    "        nbr_of_documents=len(DocumentTermsCollection)\n",
    "        TerDoc_frequency_Matrix=np.zeros((len(DistinctTerms),len(DocumentTermsCollection)))\n",
    "        \n",
    "        for term ,i in zip(DistinctTerms , range(nbr_terms)):\n",
    "            Vector=[]\n",
    "            \n",
    "            for c in DocumentTermsCollection:\n",
    "                count=0\n",
    "                for t in DocumentTermsCollection[c]:\n",
    "                    if t==term:\n",
    "                        count+=1\n",
    "                Vector.append(count)\n",
    "            TerDoc_frequency_Matrix[i]=Vector\n",
    "        return TerDoc_frequency_Matrix\n",
    "\n",
    "    \n",
    "    #Update Atribute \n",
    "    \n",
    "    \n",
    "    def TermfrequencyVector(term):\n",
    "        for i in range(len(VSM.ti)):\n",
    "            if VSM.ti[i]==term :\n",
    "                return VSM.TerDoc_frequency_Matrix[i]\n",
    "    \n",
    "    def Documentfrequency():\n",
    "        return np.sum(VSM.TerDoc_frequency_Matrix,axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # this function calculate the idf of all terms in our data \n",
    "    def idf():\n",
    "        df=Documentfrequency()\n",
    "        N=len(VSM.Di)\n",
    "        idf=np.log10(N/df)\n",
    "        return idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # this function return terms frequency raw in given doc\n",
    "    # \n",
    "    def tfraw(doc):\n",
    "        j=0\n",
    "        for i in VSM.Di:\n",
    "            j+=1\n",
    "            if doc == i:\n",
    "                return np.array(VSM.TerDoc_frequency_Matrix[0:13,j-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # tf wieght of given doc \n",
    "    def tfwght(doc):\n",
    "        tfra=tfraw(doc)\n",
    "        tfw=tfra\n",
    "        for i,j in zip(tfra,range(len(tfra))):\n",
    "            if i != 0:\n",
    "                tfw[j]=1-np.log(tfra[j])\n",
    "        return tfw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # tf*idf \n",
    "    def tf_idf(tf,idf):\n",
    "        return np.multiply(tf,idf)\n",
    "        \n",
    "    def Vector_normalization(tf_idf):\n",
    "        L=np.sqrt(np.sum(np.power(tf_idf,2)))\n",
    "        return tf_idf/L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " DOC1  :  English tutorial and fast track learning latent semantic indexing Book on semantic indexing Advance in structure and semantic indexing Analysis Analysis of latent structure \n",
      "\n",
      "\n",
      " DOC2  :  learning latent semantic indexing \n",
      "\n",
      "\n",
      " DOC3  :  Book on semantic indexing \n",
      "\n",
      "\n",
      " DOC4  :  Advance in structure and semantic indexing \n",
      "\n",
      "\n",
      " DOC5  :  Analysis Analysis of latent structure \n",
      "\n",
      "\n",
      " Q  :  latent learning \n",
      "\n",
      "\n",
      "\n",
      "Term frequency in all docs\n",
      " [[1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [2. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 1.]\n",
      " [2. 1. 0. 0. 1. 1.]\n",
      " [3. 1. 1. 1. 0. 0.]\n",
      " [3. 1. 1. 1. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0.]\n",
      " [2. 0. 0. 1. 1. 0.]\n",
      " [2. 0. 0. 0. 2. 0.]]\n",
      "TFraw(D1)\n",
      " [1. 1. 2. 1. 1. 1. 2. 3. 3. 1. 1. 2. 2.]\n",
      "TFwght(D1)\n",
      " [ 1.          1.          0.30685282  1.          1.          1.\n",
      "  0.30685282 -0.09861229 -0.09861229  1.          1.          0.30685282\n",
      "  0.30685282]\n",
      "idf\n",
      " [0.77815125 0.77815125 0.30103    0.77815125 0.77815125 0.30103\n",
      " 0.07918125 0.         0.         0.47712125 0.47712125 0.17609126\n",
      " 0.17609126]\n",
      "df\n",
      " [1. 1. 3. 1. 1. 3. 5. 6. 6. 2. 2. 4. 4.]\n",
      "tf-idf(D1)\n",
      " [0.77815125 0.77815125 0.60205999 0.77815125 0.77815125 0.30103\n",
      " 0.15836249 0.         0.         0.47712125 0.47712125 0.35218252\n",
      " 0.35218252]\n",
      "normalized Vector(D1)\n",
      " [0.40991648 0.40991648 0.31715468 0.40991648 0.40991648 0.15857734\n",
      " 0.08342259 0.         0.         0.25133914 0.25133914 0.18552359\n",
      " 0.18552359]\n"
     ]
    }
   ],
   "source": [
    "    #Test Q1 , Doc1 \n",
    "    add_Query_data(VSM.Q1)\n",
    "    displayDict(VSM.Data)\n",
    "    VSM.Ti= Terms(VSM.Data)\n",
    "    #ti\n",
    "    VSM.ti = Distinctterms(VSM.Ti)\n",
    "    #Di\n",
    "    VSM.Di= DocumentColection(VSM.Data)\n",
    "    VSM.TerDoc_frequency_Matrix=TermDocfrequencyMatrix(VSM.Di,VSM.ti)\n",
    "    print(\"Term frequency in all docs\\n\",VSM.TerDoc_frequency_Matrix)\n",
    "    VSM.df=Documentfrequency()\n",
    "    VSM.idf=idf()\n",
    "    TFrawD1=tfraw(\"DOC1\")\n",
    "    TFwght_D1=tfwght(\"DOC1\")\n",
    "    tf_idf_d1=tf_idf(TFrawD1,VSM.idf)\n",
    "    normalized_vectorD1=Vector_normalization(tf_idf_d1)\n",
    "    print(\"TFraw(D1)\\n\",TFrawD1)\n",
    "    print(\"TFwght(D1)\\n\",TFwght_D1)\n",
    "    print(\"idf\\n\",VSM.idf)\n",
    "    print(\"df\\n\",VSM.df)\n",
    "    print(\"tf-idf(D1)\\n\",tf_idf_d1)\n",
    "    print(\"normalized Vector(D1)\\n\",normalized_vectorD1)\n",
    "    delete_Query_from_Data()\n",
    "    #np.array([TFrawD1,TFwght_D1,VSM.idf,VSM.df,tf_idf_d1,normalized_vectorD1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "   def QueryAnalysis(Q):\n",
    "    Matrix={}\n",
    "    add_Query_data(Q)\n",
    "    VSM.Ti= Terms(VSM.Data)\n",
    "    #ti\n",
    "    VSM.ti = Distinctterms(VSM.Ti)\n",
    "    #Di\n",
    "    VSM.Di= DocumentColection(VSM.Data)\n",
    "    VSM.TerDoc_frequency_Matrix=TermDocfrequencyMatrix(VSM.Di,VSM.ti)\n",
    "    VSM.df=Documentfrequency()\n",
    "    VSM.idf=idf()\n",
    "    for d in VSM.Data:    \n",
    "        TFraw=tfraw(d)\n",
    "        TFwght=tfwght(d)\n",
    "        Tf_idf=tf_idf(TFraw,VSM.idf)\n",
    "        normalized_vector=Vector_normalization(Tf_idf)\n",
    "        Matrix[d]=np.array([TFraw,TFwght,VSM.df,VSM.idf,Tf_idf,normalized_vector])\n",
    "    delete_Query_from_Data()\n",
    "    return Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "   def Smart_notation(Q,doc,Smartnotation):\n",
    "    Matrix=None\n",
    "    add_Query_data(Q)\n",
    "    VSM.Ti= Terms(VSM.Data)\n",
    "    #ti\n",
    "    VSM.ti = Distinctterms(VSM.Ti)\n",
    "    #Di\n",
    "    VSM.Di= DocumentColection(VSM.Data)\n",
    "    VSM.TerDoc_frequency_Matrix=TermDocfrequencyMatrix(VSM.Di,VSM.ti)\n",
    "    VSM.df=Documentfrequency()\n",
    "    SN=Smartnotation.upper().split(\".\")\n",
    "     \n",
    "    Tf_idf=None\n",
    "    TFwght=None\n",
    "    Idf=None\n",
    "    normalized_vecto=None\n",
    "    TFraw=tfraw(doc)\n",
    "    if SN[0]==\"N\":\n",
    "        TFwght=TFraw\n",
    "    elif SN[0]==\"L\":\n",
    "        TFwght=tfwght(doc)\n",
    "\n",
    "    if SN[1]==\"N\":\n",
    "        Idf=np.zeros(len(VSM.ti))+1\n",
    "        Tf_idf=TFraw\n",
    "    elif SN[1]==\"T\":\n",
    "        Idf=idf()\n",
    "        Tf_idf=tf_idf(TFraw,Idf)\n",
    "    if SN[2]==\"N\":\n",
    "        normalized_vector=Tf_idf\n",
    "    elif SN[2]==\"C\":\n",
    "        normalized_vector=Vector_normalization(Tf_idf)\n",
    "\n",
    "    Matrix=np.array([TFraw,TFwght,VSM.df,Idf,Tf_idf,normalized_vector])\n",
    "    \n",
    "    delete_Query_from_Data()\n",
    "    return Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## convert your array into a dataframe\n",
    "#Q=QueryAnalysis(VSM.Q1)\n",
    "filepath = 'my_excel_file.xlsx'\n",
    "def final_tableScoresdisplay(Matrix):\n",
    "    #for i in Matrix:\n",
    "        df = pd.DataFrame (Matrix.T,columns=[\"TFraw\",\"TFwght\",\"df\",\"idf\",\"Tf_idf\",\"normalized_vector\"],index=VSM.ti)\n",
    "        print(\"\\n\",df)\n",
    "        return df\n",
    "\n",
    "#filepath = 'my_excel_file.xlsx'\n",
    "#df.to_excel(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            TFraw    TFwght   df       idf    Tf_idf  normalized_vector\n",
      "ENGLISH      1.0  1.000000  1.0  0.778151  0.778151           0.409916\n",
      "TUTORIAL     1.0  1.000000  1.0  0.778151  0.778151           0.409916\n",
      "AND          2.0  0.306853  3.0  0.301030  0.602060           0.317155\n",
      "FAST         1.0  1.000000  1.0  0.778151  0.778151           0.409916\n",
      "TRACK        1.0  1.000000  1.0  0.778151  0.778151           0.409916\n",
      "LEARNING     1.0  1.000000  3.0  0.301030  0.301030           0.158577\n",
      "LATENT       2.0  0.306853  5.0  0.079181  0.158362           0.083423\n",
      "SEMANTIC     3.0 -0.098612  6.0  0.000000  0.000000           0.000000\n",
      "INDEXING     3.0 -0.098612  6.0  0.000000  0.000000           0.000000\n",
      "BOOK         1.0  1.000000  2.0  0.477121  0.477121           0.251339\n",
      "ADVANCE      1.0  1.000000  2.0  0.477121  0.477121           0.251339\n",
      "STRUCTURE    2.0  0.306853  4.0  0.176091  0.352183           0.185524\n",
      "ANALYSIS     2.0  0.306853  4.0  0.176091  0.352183           0.185524\n",
      "\n",
      "            TFraw  TFwght   df       idf    Tf_idf  normalized_vector\n",
      "ENGLISH      0.0     0.0  1.0  0.778151  0.000000           0.000000\n",
      "TUTORIAL     0.0     0.0  1.0  0.778151  0.000000           0.000000\n",
      "AND          0.0     0.0  3.0  0.301030  0.000000           0.000000\n",
      "FAST         0.0     0.0  1.0  0.778151  0.000000           0.000000\n",
      "TRACK        0.0     0.0  1.0  0.778151  0.000000           0.000000\n",
      "LEARNING     1.0     1.0  3.0  0.301030  0.301030           0.967104\n",
      "LATENT       1.0     1.0  5.0  0.079181  0.079181           0.254382\n",
      "SEMANTIC     0.0     0.0  6.0  0.000000  0.000000           0.000000\n",
      "INDEXING     0.0     0.0  6.0  0.000000  0.000000           0.000000\n",
      "BOOK         0.0     0.0  2.0  0.477121  0.000000           0.000000\n",
      "ADVANCE      0.0     0.0  2.0  0.477121  0.000000           0.000000\n",
      "STRUCTURE    0.0     0.0  4.0  0.176091  0.000000           0.000000\n",
      "ANALYSIS     0.0     0.0  4.0  0.176091  0.000000           0.000000\n",
      "{'DOC1': 0.174581940900918, 'DOC2': 1.0, 'DOC3': 0.0, 'DOC4': 0.0, 'DOC5': 0.0501506943387915}\n",
      "l.l.l.n.n.n\n",
      "n.n.n\n"
     ]
    }
   ],
   "source": [
    "QD1=Smart_notation(VSM.Q1,\"DOC1\",'L.T.C')\n",
    "Q=Smart_notation(VSM.Q1,\"Q\",'L.T.C')\n",
    "final_tableScoresdisplay(QD1)\n",
    "final_tableScoresdisplay(Q)\n",
    "#final similarity score \n",
    "# input Smart notation of doc ,Smart notation of Query \n",
    "def doc_Score(SN_Doc,SN_Q):\n",
    "    return np.dot(SN_Doc[5],SN_Q[5])\n",
    "#print(\"\\nFinal similarity Score of Doc1 and Q1 = \",doc_Score(QD1,Q))\n",
    "\n",
    "def finalsimilarityscore(Query,smartnotion):\n",
    "    SN=smartnotion\n",
    "    Final_similarity_score={}\n",
    "    for d in VSM.Data:\n",
    "        QD=Smart_notation(Query,d,SN[0:5])\n",
    "        Q=Smart_notation(Query,\"Q\",SN[6:11])\n",
    "        Final_similarity_score[d]=doc_Score(QD,Q)\n",
    "    return Final_similarity_score\n",
    "#pd.DataFrame(finalsimilarityscore(VSM.Q1,\"L.T.C.L.T.C\"))\n",
    "print(finalsimilarityscore(VSM.Q1,\"L.T.C.L.T.C\"))\n",
    "a=\"l.l.l.n.n.n\"\n",
    "#a.upper().split()\n",
    "print(a)\n",
    "print(a[6:11])\n",
    "filepath = 'my_excel_file.xlsx'\n",
    "\n",
    "#final_tableScoresdisplay(QD1).to_excel(filepath)\n",
    "#final_tableScoresdisplay(Q).to_excel(\"Q.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
